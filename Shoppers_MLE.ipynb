{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f79545a6",
   "metadata": {},
   "source": [
    "## 필요 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7bb5c56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-14T05:15:33.827199Z",
     "start_time": "2023-04-14T05:15:33.807501Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from dython.nominal import compute_associations\n",
    "\n",
    "from sklearn import svm,tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.stats import wasserstein_distance\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from tabulate import tabulate\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import glob\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91f63a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def supervised_model_training(x_train, y_train, x_test, y_test, model_name):\n",
    "    if model_name == 'lr':\n",
    "        model  = LogisticRegression(random_state=42,max_iter=100) \n",
    "    elif model_name == 'svm':\n",
    "        model  = svm.SVC(random_state=42,probability=True)\n",
    "    elif model_name == 'dt':\n",
    "        model  = tree.DecisionTreeClassifier(random_state=42)\n",
    "    elif model_name  == \"mlp\":\n",
    "        model = MLPClassifier(random_state=42,max_iter=100)\n",
    "    elif model_name == 'rf':      \n",
    "        model = RandomForestClassifier(random_state=42)\n",
    "    elif model_name == 'ada':\n",
    "        model = AdaBoostClassifier(random_state = 42)\n",
    "    # elif model_name == 'xgb':\n",
    "    #     model = XGBClassifier(random_state = 42, objective='multi:softmax') # target 수를 보고 결정\n",
    "    # elif model_name == 'lgb':\n",
    "    #     model = LGBMClassifier(random_state = 42, objective='multiclass')\n",
    "    elif model_name == 'xgb':\n",
    "        model = XGBClassifier(random_state = 42, objective='binary:logistic')\n",
    "    elif model_name == 'lgb':\n",
    "        model = LGBMClassifier(random_state = 42, objective='binary')\n",
    "    \n",
    "    model.fit(x_train, y_train)\n",
    "    pred = model.predict(x_test)\n",
    "    if len(np.unique(y_train))>2:\n",
    "        predict = model.predict_proba(x_test)        \n",
    "        acc = metrics.accuracy_score(y_test,pred)*100\n",
    "        auc = metrics.roc_auc_score(y_test, predict,average=\"macro\",multi_class=\"ovr\")\n",
    "        f1_score = metrics.precision_recall_fscore_support(y_test, pred,average=\"weighted\", zero_division=1)[2]\n",
    "        return [acc, auc,f1_score] \n",
    "    else:\n",
    "        predict = model.predict_proba(x_test)[:,1]    \n",
    "        acc = metrics.accuracy_score(y_test,pred)*100\n",
    "        auc = metrics.roc_auc_score(y_test, predict)\n",
    "        f1_score = metrics.precision_recall_fscore_support(y_test,pred)[2].mean()\n",
    "        return [acc, auc,f1_score] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fca7b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_utility_metrics(real_train_path, real_test_path, fake_paths, discrete_columns, target_column, scaler=\"MinMax\", classifiers = [\"lr\",\"dt\",\"mlp\",\"rf\",\"ada\",\"xgb\",\"lgb\"], test_ratio=.20):\n",
    "    print('fake data 개수 :', len(fake_paths))\n",
    "    label_encoder_dict = {}\n",
    "\n",
    "    real_train_df = pd.read_csv(real_train_path)\n",
    "    real_test_df = pd.read_csv(real_test_path)\n",
    "    data_dim = real_train_df.shape[1]\n",
    "\n",
    "    col_order = discrete_columns\n",
    "    real_train_df = real_train_df.reindex(columns=col_order + list(real_train_df.columns.difference(col_order)))\n",
    "    real_test_df = real_test_df.reindex(columns=col_order + list(real_test_df.columns.difference(col_order)))\n",
    "\n",
    "    ## 범주형 변수 변환\n",
    "    for col in real_train_df.columns:\n",
    "        if (real_train_df[col]).dtypes == 'O':\n",
    "            le = LabelEncoder()\n",
    "            le = le.fit(real_train_df[col])\n",
    "            label_encoder_dict[col] = le\n",
    "            real_train_df[col] = le.transform(real_train_df[col])\n",
    "            real_test_df[col] = le.transform(real_test_df[col])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    ## real_train_df 데이터 분리\n",
    "    train_data_real = real_train_df.drop([target_column], axis=1, inplace=False) # 피처(독립변수)\n",
    "    train_target_real = real_train_df[target_column].astype(int) # 레이블(종속변수) -> 0,1,2의 정수형으로 맞춰줘야 xgb 에러가 안 남\n",
    "\n",
    "    ## real 평가 데이터\n",
    "    test_data_real = real_test_df.drop([target_column], axis=1, inplace=False) # 피처(독립변수)\n",
    "    test_target_real = real_test_df[target_column].astype(int)\n",
    "\n",
    "    if scaler==\"MinMax\":\n",
    "        scaler_real = MinMaxScaler()\n",
    "    else:\n",
    "        scaler_real = StandardScaler()\n",
    "    \n",
    "    ## scaling\n",
    "    scaler_real.fit(train_data_real)\n",
    "    X_train_real_scaled = scaler_real.transform(train_data_real)\n",
    "    X_test_real_scaled = scaler_real.transform(test_data_real)\n",
    "    \n",
    "    ## 분류 모델 적용\n",
    "    all_real_results = []\n",
    "    for classifier in classifiers:\n",
    "        print(\" real data classifer :\", classifier)\n",
    "        real_results = supervised_model_training(X_train_real_scaled, train_target_real, X_test_real_scaled, test_target_real, classifier)\n",
    "        all_real_results.append(real_results)\n",
    "    \n",
    "    print('## Real data ML Utility finish ##')\n",
    "    print()\n",
    "      \n",
    "    all_fake_results_avg = []\n",
    "    \n",
    "    ## fake data 불러오기\n",
    "    for fake_path in fake_paths:\n",
    "        print(\" fake_path :\", fake_path)\n",
    "        fake_train_df = pd.read_csv(fake_path)\n",
    "        fake_train_df = fake_train_df.reindex(columns=col_order + list(fake_train_df.columns.difference(col_order)))\n",
    "        for col in fake_train_df.columns:\n",
    "            if (fake_train_df[col]).dtypes == 'O':\n",
    "                le = label_encoder_dict[col]\n",
    "                fake_train_df[col] = le.transform(fake_train_df[col])\n",
    "        train_data_fake = fake_train_df.drop([target_column], axis=1, inplace=False) # 피처(독립변수)\n",
    "        train_target_fake = fake_train_df[target_column].astype(int) # 레이블(종속변수) -> 0,1,2의 정수형으로 맞춰줘야 xgb 에러가 안 남\n",
    "        print(len(np.unique(train_target_fake)))\n",
    "\n",
    "        if scaler==\"MinMax\":\n",
    "          scaler_fake = MinMaxScaler()\n",
    "        else:\n",
    "          scaler_fake = StandardScaler()\n",
    "        \n",
    "        scaler_fake.fit(train_data_fake)\n",
    "        \n",
    "        X_train_fake_scaled = scaler_fake.transform(train_data_fake)\n",
    "        \n",
    "        ## 분류 모델 적용\n",
    "        all_fake_results = []\n",
    "        for classifier in classifiers:\n",
    "            fake_results = supervised_model_training(X_train_fake_scaled, train_target_fake, X_test_real_scaled, test_target_real, classifier)\n",
    "            all_fake_results.append(fake_results)\n",
    "\n",
    "        all_fake_results_avg.append(all_fake_results)\n",
    "    \n",
    "    diff_results = np.abs(np.array(all_real_results)- np.array(all_fake_results_avg).mean(axis=0))\n",
    "\n",
    "    final_result_df = pd.DataFrame(diff_results, columns=[\"Acc\",\"AUC\",\"f1_score\"])\n",
    "\n",
    "    return final_result_df, all_real_results, all_fake_results_avg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc858aa3",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "caea12fa",
   "metadata": {},
   "source": [
    "# 1. Machine Learning Efficiacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b9a4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"shoppers\"\n",
    "real_train_path = f\"CHECK_DATASETS/{dataset}/trn_{dataset}_final.csv\"\n",
    "real_test_path = f\"CHECK_DATASETS/{dataset}/tst_{dataset}_final.csv\"\n",
    "fake_file_root = f\"FAKE_DATASETS/{dataset}\"\n",
    "discrete_columns = ['SpecialDay', 'Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend', 'Revenue']\n",
    "classifiers_list = [\"lr\",\"mlp\",\"rf\", \"ada\"]\n",
    "target_column = 'Revenue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FAKE_DATASETS/shoppers\\\\Shoppers_fake_shoppers_1.csv']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_paths = glob.glob(fake_file_root+'/'+'*')\n",
    "fake_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b95eee32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake data 개수 : 22\n",
      " real data classifer : lr\n",
      " real data classifer : mlp\n",
      " real data classifer : rf\n",
      " real data classifer : ada\n",
      "## Real data ML Utility finish ##\n",
      "\n",
      " fake_path : F\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'F'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\RohSeungchan\\Desktop\\sps.Lab\\### 연구 ###\\## 논문\\GAN\\### 논문 최종본\\## 코드 제출\\Shoppers_MLE.ipynb 셀 9\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RohSeungchan/Desktop/sps.Lab/%23%23%23%20%EC%97%B0%EA%B5%AC%20%23%23%23/%23%23%20%EB%85%BC%EB%AC%B8/GAN/%23%23%23%20%EB%85%BC%EB%AC%B8%20%EC%B5%9C%EC%A2%85%EB%B3%B8/%23%23%20%EC%BD%94%EB%93%9C%20%EC%A0%9C%EC%B6%9C/Shoppers_MLE.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m metric \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mAcc\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mAUC\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mf1_score\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RohSeungchan/Desktop/sps.Lab/%23%23%23%20%EC%97%B0%EA%B5%AC%20%23%23%23/%23%23%20%EB%85%BC%EB%AC%B8/GAN/%23%23%23%20%EB%85%BC%EB%AC%B8%20%EC%B5%9C%EC%A2%85%EB%B3%B8/%23%23%20%EC%BD%94%EB%93%9C%20%EC%A0%9C%EC%B6%9C/Shoppers_MLE.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m classifiers_list \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mmlp\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mada\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/RohSeungchan/Desktop/sps.Lab/%23%23%23%20%EC%97%B0%EA%B5%AC%20%23%23%23/%23%23%20%EB%85%BC%EB%AC%B8/GAN/%23%23%23%20%EB%85%BC%EB%AC%B8%20%EC%B5%9C%EC%A2%85%EB%B3%B8/%23%23%20%EC%BD%94%EB%93%9C%20%EC%A0%9C%EC%B6%9C/Shoppers_MLE.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m final_result_df, real_result, fake_result \u001b[39m=\u001b[39m get_utility_metrics(real_train_path, real_test_path, fake_paths, discrete_columns, target_column, \u001b[39m\"\u001b[39;49m\u001b[39mMinMax\u001b[39;49m\u001b[39m\"\u001b[39;49m, classifiers_list, test_ratio \u001b[39m=\u001b[39;49m \u001b[39m0.20\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RohSeungchan/Desktop/sps.Lab/%23%23%23%20%EC%97%B0%EA%B5%AC%20%23%23%23/%23%23%20%EB%85%BC%EB%AC%B8/GAN/%23%23%23%20%EB%85%BC%EB%AC%B8%20%EC%B5%9C%EC%A2%85%EB%B3%B8/%23%23%20%EC%BD%94%EB%93%9C%20%EC%A0%9C%EC%B6%9C/Shoppers_MLE.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m\"\"\"실제와 fake 간의 차이\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/RohSeungchan/Desktop/sps.Lab/%23%23%23%20%EC%97%B0%EA%B5%AC%20%23%23%23/%23%23%20%EB%85%BC%EB%AC%B8/GAN/%23%23%23%20%EB%85%BC%EB%AC%B8%20%EC%B5%9C%EC%A2%85%EB%B3%B8/%23%23%20%EC%BD%94%EB%93%9C%20%EC%A0%9C%EC%B6%9C/Shoppers_MLE.ipynb#X12sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m final_result_df\u001b[39m.\u001b[39mindex \u001b[39m=\u001b[39m classifiers_list\n",
      "\u001b[1;32mc:\\Users\\RohSeungchan\\Desktop\\sps.Lab\\### 연구 ###\\## 논문\\GAN\\### 논문 최종본\\## 코드 제출\\Shoppers_MLE.ipynb 셀 9\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/RohSeungchan/Desktop/sps.Lab/%23%23%23%20%EC%97%B0%EA%B5%AC%20%23%23%23/%23%23%20%EB%85%BC%EB%AC%B8/GAN/%23%23%23%20%EB%85%BC%EB%AC%B8%20%EC%B5%9C%EC%A2%85%EB%B3%B8/%23%23%20%EC%BD%94%EB%93%9C%20%EC%A0%9C%EC%B6%9C/Shoppers_MLE.ipynb#X12sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39mfor\u001b[39;00m fake_path \u001b[39min\u001b[39;00m fake_paths:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/RohSeungchan/Desktop/sps.Lab/%23%23%23%20%EC%97%B0%EA%B5%AC%20%23%23%23/%23%23%20%EB%85%BC%EB%AC%B8/GAN/%23%23%23%20%EB%85%BC%EB%AC%B8%20%EC%B5%9C%EC%A2%85%EB%B3%B8/%23%23%20%EC%BD%94%EB%93%9C%20%EC%A0%9C%EC%B6%9C/Shoppers_MLE.ipynb#X12sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m fake_path :\u001b[39m\u001b[39m\"\u001b[39m, fake_path)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/RohSeungchan/Desktop/sps.Lab/%23%23%23%20%EC%97%B0%EA%B5%AC%20%23%23%23/%23%23%20%EB%85%BC%EB%AC%B8/GAN/%23%23%23%20%EB%85%BC%EB%AC%B8%20%EC%B5%9C%EC%A2%85%EB%B3%B8/%23%23%20%EC%BD%94%EB%93%9C%20%EC%A0%9C%EC%B6%9C/Shoppers_MLE.ipynb#X12sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     fake_train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(fake_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/RohSeungchan/Desktop/sps.Lab/%23%23%23%20%EC%97%B0%EA%B5%AC%20%23%23%23/%23%23%20%EB%85%BC%EB%AC%B8/GAN/%23%23%23%20%EB%85%BC%EB%AC%B8%20%EC%B5%9C%EC%A2%85%EB%B3%B8/%23%23%20%EC%BD%94%EB%93%9C%20%EC%A0%9C%EC%B6%9C/Shoppers_MLE.ipynb#X12sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     fake_train_df \u001b[39m=\u001b[39m fake_train_df\u001b[39m.\u001b[39mreindex(columns\u001b[39m=\u001b[39mcol_order \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(fake_train_df\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mdifference(col_order)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/RohSeungchan/Desktop/sps.Lab/%23%23%23%20%EC%97%B0%EA%B5%AC%20%23%23%23/%23%23%20%EB%85%BC%EB%AC%B8/GAN/%23%23%23%20%EB%85%BC%EB%AC%B8%20%EC%B5%9C%EC%A2%85%EB%B3%B8/%23%23%20%EC%BD%94%EB%93%9C%20%EC%A0%9C%EC%B6%9C/Shoppers_MLE.ipynb#X12sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m fake_train_df\u001b[39m.\u001b[39mcolumns:\n",
      "File \u001b[1;32mc:\\Users\\RohSeungchan\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\RohSeungchan\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\RohSeungchan\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\RohSeungchan\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\RohSeungchan\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\RohSeungchan\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\RohSeungchan\\anaconda3\\envs\\torch-gpu\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'F'"
     ]
    }
   ],
   "source": [
    "metric = [\"Acc\",\"AUC\",\"f1_score\"]\n",
    "classifiers_list = [\"lr\",\"mlp\",\"rf\", \"ada\"]\n",
    "final_result_df, real_result, fake_result = get_utility_metrics(real_train_path, real_test_path, fake_paths, discrete_columns, target_column, \"MinMax\", classifiers_list, test_ratio = 0.20)\n",
    "\n",
    "\"\"\"실제와 fake 간의 차이\"\"\"\n",
    "final_result_df.index = classifiers_list\n",
    "\n",
    "\"\"\"실제 데이터\"\"\"\n",
    "real_df = pd.DataFrame(real_result, columns = metric)\n",
    "real_df.index = classifiers_list\n",
    "real_df = real_df.reset_index().rename({'index' : 'model'}, axis=1)\n",
    "\n",
    "\"\"\"fake 데이터\"\"\"\n",
    "fake_df = pd.DataFrame()\n",
    "for idx, fdf in enumerate(fake_result):\n",
    "    fdf = pd.DataFrame(fdf, columns = metric)\n",
    "    fdf.index = classifiers_list\n",
    "    fdf = fdf.reset_index().rename({'index' : 'model'}, axis=1)\n",
    "    fdf['file_order'] = idx\n",
    "    fake_df = pd.concat([fake_df, fdf], axis=0)\n",
    "fake_df = fake_df.reset_index(drop=True)\n",
    "final_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f8338e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Acc         0.941876\n",
       "AUC         0.034919\n",
       "f1_score    0.017061\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result_df.mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
